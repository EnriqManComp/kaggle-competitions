{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":20270,"databundleVersionId":1222630,"sourceType":"competition"}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport time\n\n# Visualization\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport missingno as msno\nsns.set_style(\"darkgrid\")\n\ncolor_continuous_blue_sequence = [\"#B3E5FC\",\"#81D4FA\",\"#4FC3F7\",\"#29B6F6\",\"#03A9F4\",\"#039BE5\",\"#0288D1\",\"#0277BD\",\"#01579B\",\"#003366\"]\n\n# PyTorch\nimport torch as T\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport torch.nn.functional as F\nfrom torchvision import io\nfrom torchvision import transforms\nimport cv2\n\n# Configure GPU\ndevice = T.device('cuda' if T.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-13T19:06:06.407426Z","iopub.execute_input":"2024-04-13T19:06:06.407786Z","iopub.status.idle":"2024-04-13T19:06:13.556185Z","shell.execute_reply.started":"2024-04-13T19:06:06.407752Z","shell.execute_reply":"2024-04-13T19:06:13.554796Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import warnings\nimport random\nwarnings.simplefilter('ignore')\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    T.manual_seed(seed)\n    T.cuda.manual_seed(seed)\n    T.backends.cudnn.deterministic = True\n    T.backends.cudnn.benchmark = True\n    \nseed_everything(47)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:07:03.803463Z","iopub.execute_input":"2024-04-13T19:07:03.803987Z","iopub.status.idle":"2024-04-13T19:07:03.815765Z","shell.execute_reply.started":"2024-04-13T19:07:03.803945Z","shell.execute_reply":"2024-04-13T19:07:03.814306Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"# Read data\ntrain_dataset = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/train.csv\")\n# Dataset dimensions\nprint(f\"Shape of the dataset: {train_dataset.shape}\")\n# Dataset memory usage\nprint('Dataset Memory Usage = {:.2f} MB'.format(train_dataset.memory_usage().sum() / 1024**2))\n# Show data sample\ntrain_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:13:51.426745Z","iopub.execute_input":"2024-04-13T19:13:51.427620Z","iopub.status.idle":"2024-04-13T19:13:51.553265Z","shell.execute_reply.started":"2024-04-13T19:13:51.427578Z","shell.execute_reply":"2024-04-13T19:13:51.552243Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Shape of the dataset: (33126, 8)\nDataset Memory Usage = 2.02 MB\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n\n  diagnosis benign_malignant  target  \n0   unknown           benign       0  \n1   unknown           benign       0  \n2     nevus           benign       0  \n3   unknown           benign       0  \n4   unknown           benign       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>patient_id</th>\n      <th>sex</th>\n      <th>age_approx</th>\n      <th>anatom_site_general_challenge</th>\n      <th>diagnosis</th>\n      <th>benign_malignant</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_2637011</td>\n      <td>IP_7279968</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015719</td>\n      <td>IP_3075186</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0068279</td>\n      <td>IP_6890425</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0074268</td>\n      <td>IP_8723313</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"train_dataset['benign_malignant'].value_counts().plot(kind='pie', figsize=(8,8))\nplt.title(\"Proportion of Malignant and Benign Categories in the Dataset\")\nplt.ylabel(\"\")\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.countplot(data=train_dataset, x='sex', hue='benign_malignant')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remove target redundant column","metadata":{}},{"cell_type":"code","source":"train_dataset = train_dataset.drop(['benign_malignant'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:13:54.581500Z","iopub.execute_input":"2024-04-13T19:13:54.584335Z","iopub.status.idle":"2024-04-13T19:13:54.596051Z","shell.execute_reply.started":"2024-04-13T19:13:54.584278Z","shell.execute_reply":"2024-04-13T19:13:54.594372Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Missing values","metadata":{}},{"cell_type":"code","source":"msno.matrix(train_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count of missing values\nprint(\"Count of missing values by columns: \\n\")\ntrain_dataset.isna().sum().sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset samples","metadata":{}},{"cell_type":"code","source":"images = train_dataset.loc[train_dataset['target']==1].sample(10)['image_name'].values\nplt.figure(figsize=(16,8))\nfor idx, image_name in enumerate(images):\n    image = cv2.imread(f\"/kaggle/input/siim-isic-melanoma-classification/jpeg/train/{image_name}.jpg\")\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    plt.subplot(2,5, idx+1)\n    plt.axis('off')\n    plt.imshow(image)\nplt.suptitle(\"Images with Malignt Melanoma\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = train_dataset.loc[train_dataset['target']==0].sample(10)['image_name'].values\nplt.figure(figsize=(16,8))\nfor idx, image_name in enumerate(images):\n    image = cv2.imread(f\"/kaggle/input/siim-isic-melanoma-classification/jpeg/train/{image_name}.jpg\")\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    plt.subplot(2,5, idx+1)\n    plt.axis('off')\n    plt.imshow(image)\nplt.suptitle(\"Images with Benign Melanoma\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Custom Dataset","metadata":{}},{"cell_type":"code","source":"class MelanomaDataset(Dataset):\n    \n    def __init__(self, df: pd.DataFrame, imfolder: str, train: bool = True, transforms = None, meta_features = None):\n        self.df = df\n        self.imfolder = imfolder\n        self.train = train\n        self.transforms = transforms\n        self.meta_features = meta_features\n        \n    def __getitem__(self, index):\n        # Path of the images\n        im_path = os.path.join(self.imfolder, self.df.iloc[index]['image_name'] + '.jpg')\n        # Read image\n        x = cv2.imread(im_path)\n        # Read meta features associated to the image\n        meta = np.array(self.df.iloc[index][self.meta_features].values, dtype=np.float32)\n        # Apply transformations to the image\n        x = to_pil_image(x)\n        if self.transforms:\n            x = self.transforms(x)\n        # Get the numerical target label (0->benign, 1->malign) \n        if self.train:\n            y = self.df.iloc[index]['target']\n            return (x, meta), y\n        else:\n            # For test data\n            return (x, meta)\n    def __len__(self):\n        # Return the length of the DataFrame\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:14:06.766595Z","iopub.execute_input":"2024-04-13T19:14:06.767751Z","iopub.status.idle":"2024-04-13T19:14:06.779081Z","shell.execute_reply.started":"2024-04-13T19:14:06.767701Z","shell.execute_reply":"2024-04-13T19:14:06.777414Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Network architecture","metadata":{}},{"cell_type":"code","source":"class Network(nn.Module):\n    def __init__(self, base_model, n_meta_features: int, device: str):\n        super(Network, self).__init__()\n        \n        self.base_model = base_model\n        for param in self.base_model.parameters():\n            param.required_grad = False\n            \n        # Images Stream        \n        # Add the stream at the end of pre-trained model\n        \n        self.base_model.fc = nn.Linear(\n            self.base_model.fc.in_features,\n            500\n        )\n        \n        # Meta Feature Stream\n        self.meta = nn.Sequential(\n            nn.Linear(n_meta_features,500),\n            nn.BatchNorm1d(500),\n            nn.ReLU(),\n            nn.Dropout(p=0.2),\n            nn.Linear(500,250),\n            nn.BatchNorm1d(250),\n            nn.ReLU(),\n            nn.Dropout(p=0.2)\n        )\n        \n        # Output layer\n        self.output = nn.Linear(500 + 250, 1)        \n        # Device\n        self.to(device)\n        # Optimizer\n        self.optim = T.optim.Adam(self.parameters(), lr=0.001)\n        # Learning Rate decay and Early Stopping Configuration\n        self.early_stop = ReduceLROnPlateau(\n            optimizer=self.optim,\n            mode=\"max\",\n            patience=1,\n            verbose=True,\n            factor=0.2\n        )\n        # Loss\n        self.loss = nn.BCEWithLogitsLoss()\n\n    def forward(self, inputs):\n        x, meta = inputs\n        cnn_features = self.base_model(x)\n        meta_features = self.meta(meta)\n        features = T.cat((cnn_features, meta_features), dim=1)\n        output = self.output(features)\n        return output                ","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:14:09.103844Z","iopub.execute_input":"2024-04-13T19:14:09.104298Z","iopub.status.idle":"2024-04-13T19:14:09.121103Z","shell.execute_reply.started":"2024-04-13T19:14:09.104266Z","shell.execute_reply":"2024-04-13T19:14:09.119583Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Augmentation Data","metadata":{}},{"cell_type":"code","source":"train_transforms = transforms.Compose([\n    transforms.RandomResizedCrop(size=(256, 256)),\n    transforms.RandomHorizontalFlip(),    \n    transforms.RandomVerticalFlip(),    \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])    \n])\n\ntest_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:14:12.167009Z","iopub.execute_input":"2024-04-13T19:14:12.167432Z","iopub.status.idle":"2024-04-13T19:14:12.175867Z","shell.execute_reply.started":"2024-04-13T19:14:12.167401Z","shell.execute_reply":"2024-04-13T19:14:12.174787Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"from torchvision import models","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:25:38.687147Z","iopub.execute_input":"2024-04-13T19:25:38.687638Z","iopub.status.idle":"2024-04-13T19:25:38.693901Z","shell.execute_reply.started":"2024-04-13T19:25:38.687602Z","shell.execute_reply":"2024-04-13T19:25:38.692426Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing Data","metadata":{}},{"cell_type":"markdown","source":"### One hot encoding of categorical feature","metadata":{}},{"cell_type":"code","source":"train_dataset.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummies_features = pd.get_dummies(train_dataset['anatom_site_general_challenge'], dummy_na=True, prefix='location')\ntrain_dataset = pd.concat([train_dataset, dummies_features.iloc[:train_dataset.shape[0]]], axis=1)\ntrain_dataset = train_dataset.drop(['anatom_site_general_challenge'], axis=1)\n# Standarize the sex feature\ntrain_dataset['sex'] = train_dataset['sex'].map({'male': 1, 'female': 0})\ntrain_dataset['sex'] = train_dataset['sex'].fillna(-1)\n\n# Normalize the age feature\ntrain_dataset['age_approx'] /= train_dataset['age_approx'].max()\ntrain_dataset['age_approx'].fillna(0)\n\n# Fill NaN values of patient id\ntrain_dataset['patient_id'] = train_dataset['patient_id'].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:14:17.150445Z","iopub.execute_input":"2024-04-13T19:14:17.151824Z","iopub.status.idle":"2024-04-13T19:14:17.191506Z","shell.execute_reply.started":"2024-04-13T19:14:17.151768Z","shell.execute_reply":"2024-04-13T19:14:17.190058Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:14:21.999864Z","iopub.execute_input":"2024-04-13T19:14:22.000434Z","iopub.status.idle":"2024-04-13T19:14:22.025390Z","shell.execute_reply.started":"2024-04-13T19:14:22.000393Z","shell.execute_reply":"2024-04-13T19:14:22.023919Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"     image_name  patient_id  sex  age_approx diagnosis  target  \\\n0  ISIC_2637011  IP_7279968  1.0    0.500000   unknown       0   \n1  ISIC_0015719  IP_3075186  0.0    0.500000   unknown       0   \n2  ISIC_0052212  IP_2842074  0.0    0.555556     nevus       0   \n3  ISIC_0068279  IP_6890425  0.0    0.500000   unknown       0   \n4  ISIC_0074268  IP_8723313  0.0    0.611111   unknown       0   \n\n   location_head/neck  location_lower extremity  location_oral/genital  \\\n0                True                     False                  False   \n1               False                     False                  False   \n2               False                      True                  False   \n3                True                     False                  False   \n4               False                     False                  False   \n\n   location_palms/soles  location_torso  location_upper extremity  \\\n0                 False           False                     False   \n1                 False           False                      True   \n2                 False           False                     False   \n3                 False           False                     False   \n4                 False           False                      True   \n\n   location_nan  \n0         False  \n1         False  \n2         False  \n3         False  \n4         False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>patient_id</th>\n      <th>sex</th>\n      <th>age_approx</th>\n      <th>diagnosis</th>\n      <th>target</th>\n      <th>location_head/neck</th>\n      <th>location_lower extremity</th>\n      <th>location_oral/genital</th>\n      <th>location_palms/soles</th>\n      <th>location_torso</th>\n      <th>location_upper extremity</th>\n      <th>location_nan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_2637011</td>\n      <td>IP_7279968</td>\n      <td>1.0</td>\n      <td>0.500000</td>\n      <td>unknown</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015719</td>\n      <td>IP_3075186</td>\n      <td>0.0</td>\n      <td>0.500000</td>\n      <td>unknown</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>0.0</td>\n      <td>0.555556</td>\n      <td>nevus</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0068279</td>\n      <td>IP_6890425</td>\n      <td>0.0</td>\n      <td>0.500000</td>\n      <td>unknown</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0074268</td>\n      <td>IP_8723313</td>\n      <td>0.0</td>\n      <td>0.611111</td>\n      <td>unknown</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"meta_features = ['sex', 'age_approx'] + [col for col in train_dataset.columns if 'location_' in col]","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:14:20.597608Z","iopub.execute_input":"2024-04-13T19:14:20.598182Z","iopub.status.idle":"2024-04-13T19:14:20.605564Z","shell.execute_reply.started":"2024-04-13T19:14:20.598140Z","shell.execute_reply":"2024-04-13T19:14:20.603828Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:14:25.872995Z","iopub.execute_input":"2024-04-13T19:14:25.873524Z","iopub.status.idle":"2024-04-13T19:14:25.992290Z","shell.execute_reply.started":"2024-04-13T19:14:25.873488Z","shell.execute_reply":"2024-04-13T19:14:25.990471Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"n_folds = 5\nkf = KFold(n_folds)\ngkf = GroupKFold(n_folds)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:14:27.511611Z","iopub.execute_input":"2024-04-13T19:14:27.512159Z","iopub.status.idle":"2024-04-13T19:14:27.519549Z","shell.execute_reply.started":"2024-04-13T19:14:27.512119Z","shell.execute_reply":"2024-04-13T19:14:27.517672Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Split dataset","metadata":{}},{"cell_type":"code","source":"y = train_dataset.loc[:,'target']\nX = train_dataset.drop(['target'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:14:29.870289Z","iopub.execute_input":"2024-04-13T19:14:29.870788Z","iopub.status.idle":"2024-04-13T19:14:29.881901Z","shell.execute_reply.started":"2024-04-13T19:14:29.870750Z","shell.execute_reply":"2024-04-13T19:14:29.880379Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from torchvision.transforms.functional import to_pil_image","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:14:31.824376Z","iopub.execute_input":"2024-04-13T19:14:31.824837Z","iopub.status.idle":"2024-04-13T19:14:31.831371Z","shell.execute_reply.started":"2024-04-13T19:14:31.824805Z","shell.execute_reply":"2024-04-13T19:14:31.829987Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Number of epochs\nepochs = 20 \n# Early Stop patience\nes_patience = 3\n# Test Time Augmentation rounds\nTTA = 3\n\nfor fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, X['patient_id'])):\n    \n    print('='*20, \"Fold: \", fold, '='*20)    \n    print(\"Train idx: \",train_idx)\n    print(\"Validation idx: \",val_idx)\n    # Save path of the model\n    model_path = f\"model_{fold}.pth\"\n    # Best validation score\n    best_val = 0\n    # Patience of the scheduler\n    patience = es_patience\n    # Pretrained model    \n    base_model = models.resnet152(pretrained=True)\n    # Model declaration one for each fold\n    model = Network(\n        base_model = base_model,\n        n_meta_features= len(meta_features),\n        device= device        \n    )\n    # Create the train dataset for each fold    \n    train = MelanomaDataset(\n        df=train_dataset.iloc[train_idx].reset_index(drop=True),\n        imfolder='/kaggle/input/siim-isic-melanoma-classification/jpeg/train/',\n        train=True,  \n        transforms=train_transforms,\n        meta_features=meta_features\n    )\n    # Create the validation dataset for each fold\n    val = MelanomaDataset(\n        df=train_dataset.iloc[val_idx].reset_index(drop=True),\n        imfolder='/kaggle/input/siim-isic-melanoma-classification/jpeg/train/',\n        train=True,  \n        transforms=test_transforms,\n        meta_features=meta_features\n    )\n    # Get the training data (image (and transformations), meta_features, y)\n    train_loader = DataLoader(\n        dataset=train,\n        batch_size=64,\n        shuffle=True,\n        num_workers=1\n    )\n    # Get the validation data (image (and transformations), meta_features, y)\n    val_loader = DataLoader(\n        dataset=train,\n        batch_size=64,\n        shuffle=True,\n        num_workers=1\n    )\n    \n    \n    for epoch in range(epochs):\n        # Training process\n        correct = 0 # Count of correct predictions\n        # Training mode\n        model.train()\n        # Training with the data in train_loader\n        for x, y in train_loader:\n            # Convert the images in a tensor\n            x[0] = T.tensor(x[0], device=device, dtype=T.float32)\n            # Convert the meta_features in a tensor\n            x[1] = T.tensor(x[1], device=device, dtype=T.float32)\n            # Convert the target in a tensor\n            y = T.tensor(y, device=device, dtype=T.float32)\n            # Reset gradients of the optimizer\n            model.optim.zero_grad()\n            # Predictions with the data (image, meta_features)\n            y_pred = model(x)\n            # Compute the loss\n            loss = model.loss(y_pred, y.unsqueeze(1))\n            # Compute backpropagation\n            loss.backward()\n            model.optim.step()\n            print(y_pred)\n            pred = T.round(T.sigmoid(y_pred))\n            # If the prediction is equal to the target increase correct by 1\n            correct += (pred.cpu() == y.cpu().unsqueeze(1)).sum().item()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:26:04.677126Z","iopub.execute_input":"2024-04-13T19:26:04.679745Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"==================== Fold:  0 ====================\nTrain idx:  [    0     1     3 ... 33123 33124 33125]\nValidation idx:  [    2     5    10 ... 33107 33109 33122]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Number of epochs\nepochs = 12 \n# Early Stop patience\nes_patience = 3\n# Test Time Augmentation rounds\nTTA = 3\n\nout_of_folds = np.zeros((len(train_dataset), 1))\nskf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx, validation_idx) in enumerate(skf.split(X = np.zeros(len(train_dataset)), y=train_dataset['target'], groups=train_dataset['patient_id'].tolist()), 1):\n    print('='*20, \"Fold: \", fold, '='*20)\n    # Path to save the model\n    model_path = f\"model_{fold}.pth\"\n    # Best validation score\n    best_val = 0\n    patience = es_patience\n    base_model = models.resnet152(pretrained=True)\n    model = Network(\n        base_model = base_model,\n        n_meta_features= len(meta_features),\n        device= device        \n    )\n\n    train = MelanomaDataset(\n        df=train_dataset.iloc[train_idx].reset_index(drop=True),\n        imfolder='/kaggle/input/siim-isic-melanoma-classification/jpeg/train/',\n        train=True,\n        transforms=train_transforms,\n        meta_features=meta_features\n    )\n    validation = MelanomaDataset(\n        df=train_dataset.iloc[validation_idx].reset_index(drop=True),\n        imfolder='/kaggle/input/siim-isic-melanoma-classification/jpeg/train/',\n        train=True,\n        transforms=test_transforms,\n        meta_features=meta_features\n    )\n    \n    train_loader = DataLoader(\n        dataset=train,\n        batch_size=64,\n        shuffle=True,\n        num_workers=1\n    )\n    validation_loader = DataLoader(\n        dataset=validation,\n        batch_size=64,\n        shuffle=True,\n        num_workers=1\n    )\n    \n    for epoch in range(epochs):\n        start_time = time.time()\n        correct = 0\n        epoch_loss = 0\n        model.train()\n        \n        for x, y in train_loader:\n            x[0] = torch.tensor(x[0], device=device, dtype=torch.float32)\n            \n            x[1] = torch.tensor(x[1], device=device, dtype=torch.float32)\n            \n            y = torch.tensor(y, device=device, dtype=torch.float32)\n            \n            model.optim.zero_grad()\n            z = model(x)\n            loss = model.loss(z, y.unsqueeze(1))\n            loss.backward()\n            model.optim.step()\n            pred = T.round(T.sigmoid(z))\n            \n            correct += (pred.cpu() == y.cpu().unsqueeze(1)).sum().item()\n            \n            epoch_loss += loss.item()\n        train_acc = correct / len(train_idx)\n        \n        model.eval()\n        val_preds = T.zeros((len(validation_idx),1), dtype=T.float32, device=device)\n        with T.no_grad():\n            for j, (x_validation, y_validation) in enumerate(validation_loader):\n                x_validation[0] = T.tensor(x_validation[0], device=device, dtype=T.float32)\n                x_validation[1] = T.tensor(x_validation[1], device=device, dtype=T.float32)\n                y_validation = T.tensor(y_validation, device=device, dtype=T.float32)\n                \n                z_validation = model(x_validation)\n                val_pred = T.sigmoid(z_validation)\n                val_preds[j*validation_loader.batch_size:j*validation_loader.batch_size+x_validation[0].shape[0]] = val_pred\n                \n                val_acc = accuracy_score(train_dataset.iloc[validation_idx]['target'].values, T.round(val_preds.cpu()))\n                val_roc = roc_auc_score(train_dataset.iloc[validation_idx]['target'].values, val_preds.cpu())\n                \n                print(\"Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Validation acc {:.3f} | Training time: {}\".format(\n                    epoch +1,\n                    epoch_loss,\n                    train_acc,\n                    val_acc,\n                    val_roc,\n                    str(datetime.timedelta(seconds=time.time() - start_time))[:7]\n                ))\n                \n                model.early_stop.step(val_roc)\n                \n                if val_roc >= best_val:\n                    best_val = val_roc\n                    patience = es_patience\n                    T.save(model, model_path)\n                else:\n                    patience -= 1\n                    if patience == 0:\n                        print(\"Early stopping. Best Val roc_auc: {:.3f}\".format(best_val))\n                        break\n        # Load the best model\n        model = T.load(model_path)  \n        model.eval()\n        val_preds = T.zeros((len(val_idx), 1), dtype=T.float32, device=device)\n        with T.no_grad():\n            for j, (x_val, y_val) in enumerate(val_loader):\n                x_val[0] = T.tensor(x_val[0], device=device, dtype=T.float32)\n                x_val[1] = T.tensor(x_val[1], device=device, dtype=T.float32)\n                y_val = T.tensor(y_val, device=device, dtype=T.float32)\n                \n                z_val = model(x_val)\n                val_pred = T.sigmoid(z_val)\n                val_preds[j*val_loader.batch_size:j*val_loader.batch_size + x_val[0].shape[0]] = val_pred\n                out_of_fold[val_idx] = val_preds.cpu().numpy()\n                \n                \n            \n                \n                ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}